{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73c90621",
   "metadata": {},
   "source": [
    "# MNIST Classification with PyTorch\n",
    "In this notebook, we'll extend our knowledge of neural networks to classify handwritten digits from the MNIST dataset using PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d758d690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbae1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edc6f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec0c5d2",
   "metadata": {
    "magic_args": "[markdown]"
   },
   "source": [
    "## Part 1: Understanding the MNIST Dataset\n",
    "\n",
    "MNIST is a widely used dataset in machine learning, consisting of 28x28 grayscale images of handwritten digits (0-9).\n",
    "It contains 60,000 training images and 10,000 test images, each with a label indicating which digit it represents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b803e50-23d7-4d83-98fa-6991551d1c0e",
   "metadata": {},
   "source": [
    "## Read the article about mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a79b37-52d3-455c-a112-0203b0ec130f",
   "metadata": {},
   "source": [
    "[https://en.wikipedia.org/wiki/MNIST_database](https://en.wikipedia.org/wiki/MNIST_database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d86cdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Define the transformations to apply to our data\n",
    "transform = transforms.Compose([\n",
    "    transforms....,                     # Convert images to PyTorch tensors\n",
    "    transforms.Normalize(...) # Normalize with mean and std of MNIST\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207327ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and load the MNIST dataset\n",
    "mnist_dataset = ...  # TODO: Load the MNIST dataset with train=True, download=True and apply the transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d5e0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the dataset size\n",
    "print(f\"Dataset size: {len(mnist_dataset)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f8a20c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e443df39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Let's visualize some examples from the dataset\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "axes = axes.flatten()\n",
    "for i in range(10):\n",
    "    img, label = mnist_dataset[i]\n",
    "    img = ...  # TODO: Convert the tensor to numpy and remove the channel dimension\n",
    "    axes[i].imshow(img, cmap='gray')\n",
    "    axes[i].set_title(f\"Digit: {label}\")\n",
    "    axes[i].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62f1a11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1cc6d7b5",
   "metadata": {
    "magic_args": "[markdown]"
   },
   "source": [
    "## Part 2: Train/Test Split - Why It's Important\n",
    "\n",
    "Splitting data into training and testing sets is a fundamental practice in machine learning:\n",
    "\n",
    "1. **Avoiding Overfitting**: Testing on unseen data helps us evaluate if our model generalizes well\n",
    "2. **Unbiased Evaluation**: Provides an honest assessment of model performance\n",
    "3. **Model Selection**: Helps in selecting the best model architecture/hyperparameters\n",
    "\n",
    "PyTorch makes this easy with built-in functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620a9e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# MNIST actually comes with a predefined test set, but let's create a validation set from our training data\n",
    "train_size = int(0.8 * len(mnist_dataset))\n",
    "val_size = len(mnist_dataset) - train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90ea1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly split the training dataset\n",
    "train_dataset, val_dataset = ...  # TODO: Split the mnist_dataset into train_dataset and val_dataset with the sizes above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f90ea03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training set size: {len(train_dataset)}\")\n",
    "print(f\"Validation set size: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8567166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders for batch processing\n",
    "batch_size = 64\n",
    "train_loader = ...(..., batch_size=batch_size, shuffle=True)\n",
    "val_loader = ...(..., batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2296b0f0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Get a sample batch\n",
    "images, labels = next(iter(train_loader))\n",
    "print(f\"Batch shape: {images.shape}\")  # Should be [batch_size, 1, 28, 28]\n",
    "print(f\"Labels shape: {labels.shape}\")  # Should be [batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab5259b",
   "metadata": {
    "magic_args": "[markdown]"
   },
   "source": [
    "## Part 3: Building a Multi-Layer Perceptron (MLP)\n",
    "\n",
    "Now we'll build a simple Multi-Layer Perceptron (MLP) to classify the MNIST digits.\n",
    "\n",
    "Our architecture will be:\n",
    "- Input layer: 784 neurons (28x28 pixels flattened)\n",
    "- Hidden layer: 128 neurons with ReLU activation\n",
    "- Output layer: 10 neurons (one for each digit) with softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d0f90c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "# Define our MLP model\n",
    "class MNISTClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTClassifier, self).__init__()\n",
    "        # Network layers\n",
    "        self.flatten = ...  # TODO: Create a layer to flatten the input images\n",
    "        self.fc1 = ...      # TODO: Create a linear layer from 28*28 to 128 neurons\n",
    "        self.relu = ...     # TODO: Define a ReLU activation\n",
    "        self.fc2 = ...      # TODO: Create a linear layer from 128 to 10 neurons (output)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Forward pass through the network\n",
    "        x = ...  # TODO: Flatten the input\n",
    "        x = ...  # TODO: Apply the first linear layer\n",
    "        x = ...  # TODO: Apply ReLU activation\n",
    "        x = ...  # TODO: Apply the output layer\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d55030f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of our model and move it to the device (CPU/GPU)\n",
    "model = MNISTClassifier().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff4f0a7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "# Define loss function and optimizer\n",
    "criterion = ...  # TODO: Define the CrossEntropyLoss\n",
    "optimizer = ...  # TODO: Define an SGD optimizer with learning rate 0.01 and momentum 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f24470",
   "metadata": {
    "magic_args": "[markdown]"
   },
   "source": [
    "## Part 4: Training the Network\n",
    "\n",
    "Now we'll train our network using the training data.\n",
    "During training, we'll:\n",
    "1. Feed batches of images through the network\n",
    "2. Calculate the loss using cross-entropy\n",
    "3. Backpropagate the gradients\n",
    "4. Update the weights\n",
    "\n",
    "We'll also periodically evaluate the model on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149f80e2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "# Function to calculate accuracy\n",
    "def calculate_accuracy(model, data_loader, device):\n",
    "    model....()  # Set model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_...():  # Disable gradient calculation for inference\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.to(...), labels.to(...)\n",
    "            outputs = model(...)\n",
    "            _, predicted = torch....(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2e94a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "train_losses = []\n",
    "val_accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3353c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Move tensors to the device\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = ...  # TODO: Forward pass through the model\n",
    "        loss = ...     # TODO: Calculate the loss using criterion, outputs and labels\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        optimizer....()  # Clear gradients\n",
    "        loss....()        # Backpropagation\n",
    "        optimizer....()       # Update weights\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Print statistics every 100 mini-batches\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Batch [{i+1}/{len(train_loader)}], Loss: {running_loss/100:.4f}')\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    # Calculate validation accuracy at the end of each epoch\n",
    "    val_accuracy = calculate_accuracy(model, val_loader, device)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Validation Accuracy: {val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0587377",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0080e906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Plot the validation accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, num_epochs+1), val_accuracies, marker='o')\n",
    "plt.title('Validation Accuracy over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578ef040",
   "metadata": {
    "magic_args": "[markdown]"
   },
   "source": [
    "## Part 5: Testing on Unseen Data\n",
    "\n",
    "Finally, let's evaluate our model on the official MNIST test set, which contains images our model has never seen before.\n",
    "This gives us the most accurate assessment of how well our model will perform in real-world scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7b9dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Load the official MNIST test set\n",
    "test_dataset = ...  # TODO: Load the MNIST dataset with train=False, download=True and apply the transform\n",
    "test_loader = ...(..., batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7507d6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy on the test set\n",
    "test_accuracy = calculate_accuracy(model, test_loader, device)\n",
    "print(f'Accuracy on the test set: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfea2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Visualize some predictions\n",
    "model.eval()  # Set the model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6190c3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first batch from the test loader\n",
    "test_images, test_labels = next(iter(test_loader))\n",
    "test_images, test_labels = test_images.to(device), test_labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3598c2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "with torch.no_grad():\n",
    "    outputs = model(test_images)\n",
    "    _, predicted = torch.max(outputs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82f7bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move tensors back to CPU for visualization\n",
    "test_images = test_images.cpu()\n",
    "test_labels = test_labels.cpu()\n",
    "predicted = predicted.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f11621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 10 images with their true and predicted labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9ab13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "axes = axes.flatten()\n",
    "for i in range(10):\n",
    "    img = test_images[i].s...().n...()\n",
    "    axes[i].imshow(img, cmap='gray')\n",
    "    color = 'green' if predicted[i] == test_labels[i] else 'red'\n",
    "    axes[i].set_title(f\"True: {test_labels[i]}\\nPred: {predicted[i]}\", color=color)\n",
    "    axes[i].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773e4b20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
